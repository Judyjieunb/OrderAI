"""
STEP 4: ìœ ì‚¬ìŠ¤íƒ€ì¼ ë§µí•‘ â†’ ë‹¹ì‹œì¦Œ(26S) ë°œì£¼ ì œì•ˆ

ì „ì‹œì¦Œ(25S) STEP2/3 ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ML ìœ ì‚¬ìŠ¤íƒ€ì¼ ë§µí•‘ì„ í†µí•´
26S ì‹ ê·œ ìŠ¤íƒ€ì¼ì˜ ì¶”ì²œ ë°œì£¼ëŸ‰ì„ ì‚°ì¶œí•©ë‹ˆë‹¤.

ì‹¤í–‰ ìˆœì„œ: STEP1 â†’ STEP2 â†’ STEP3 â†’ STEP4 (ë§ˆì§€ë§‰)
"""

import os
import sys
import json
import math
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Dict, List, Optional

import pandas as pd
import numpy as np

# â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")
OUTPUT_DIR = os.path.join(BASE_DIR, "output")

ANALYSIS_RESULT_FILE = os.path.join(OUTPUT_DIR, "25S_TimeSeries_Analysis_Result.xlsx")
DEFAULT_MAPPING_FILE = os.path.join(DATA_DIR, "similarity_mapping.csv")
SAMPLE_MAPPING_FILE = os.path.join(DATA_DIR, "similarity_mapping_sample.csv")

OUTPUT_EXCEL = os.path.join(OUTPUT_DIR, "26S_Order_Recommendation.xlsx")
OUTPUT_JSON = os.path.join(OUTPUT_DIR, "26S_Order_Recommendation.json")

# â”€â”€ ìƒìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MIN_SCORE = 0.50          # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
NEW_SEASON = "26S"
REF_SEASON = "25S"

# STEP2/3 ê²°ê³¼ ì»¬ëŸ¼ëª… (ì‹¤ì œ Excel ê¸°ì¤€)
COL_PART_CD = "PART_CD"
COL_ITEM_NM = "ITEM_NM"
COL_PRICE = "íŒë§¤ê°€"
COL_COLOR_CD = "COLOR_CD"
COL_TOTAL_ORDER = "ì´ë°œì£¼"
COL_TOTAL_INBOUND = "ì´ì…ê³ "
COL_TOTAL_SALE = "ì´íŒë§¤"
COL_SELL_RATE = "ìµœì¢…íŒë§¤ìœ¨"
COL_AI_DIAG = "AI_ì§„ë‹¨"
COL_AI_OPP_COST = "AI ê³„ì‚° ê¸°íšŒë¹„ìš©"
COL_AI_ORDER = "AIì œì•ˆ ë°œì£¼ëŸ‰"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë°ì´í„° ì†ŒìŠ¤ ì¶”ìƒí™”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MappingDataSource(ABC):
    """ML ë§µí•‘ ë°ì´í„° ì†ŒìŠ¤ ì¸í„°í˜ì´ìŠ¤"""
    @abstractmethod
    def load_mappings(self) -> pd.DataFrame:
        """ë§µí•‘ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜.

        í•„ìˆ˜ ì»¬ëŸ¼: NEW_PART_CD, NEW_ITEM_NM, NEW_CLASS2,
                   REF_PART_CD_1~3, REF_SCORE_1~3, MATCHED_ATTRS
        """
        ...


class CSVMappingSource(MappingDataSource):
    """CSV íŒŒì¼ì—ì„œ ë§µí•‘ ë¡œë“œ"""
    def __init__(self, filepath: str):
        self.filepath = filepath

    def load_mappings(self) -> pd.DataFrame:
        df = pd.read_csv(self.filepath, encoding="utf-8-sig")
        return df


class DBMappingSource(MappingDataSource):
    """í–¥í›„ Snowflake ë“± DB ì—°ë™ìš© (ë¯¸êµ¬í˜„)"""
    def __init__(self, **kwargs):
        self.config = kwargs

    def load_mappings(self) -> pd.DataFrame:
        raise NotImplementedError("DB ë§µí•‘ ì†ŒìŠ¤ëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


class APIMappingSource(MappingDataSource):
    """í–¥í›„ API ì—°ë™ìš© (ë¯¸êµ¬í˜„)"""
    def __init__(self, **kwargs):
        self.config = kwargs

    def load_mappings(self) -> pd.DataFrame:
        raise NotImplementedError("API ë§µí•‘ ì†ŒìŠ¤ëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def get_mapping_source(source_type: str = "csv", **kwargs) -> MappingDataSource:
    """íŒ©í† ë¦¬ í•¨ìˆ˜: ì†ŒìŠ¤ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ MappingDataSource ë°˜í™˜"""
    sources = {
        "csv": CSVMappingSource,
        "db": DBMappingSource,
        "api": APIMappingSource,
    }
    cls = sources.get(source_type)
    if cls is None:
        raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì†ŒìŠ¤ íƒ€ì…: {source_type}")
    return cls(**kwargs)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í•µì‹¬ ë¡œì§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def ceil_10(x):
    """10ë‹¨ìœ„ ì˜¬ë¦¼"""
    if pd.isna(x) or x <= 0:
        return 0
    return int(math.ceil(x / 10) * 10)


def load_analysis_result() -> pd.DataFrame:
    """STEP2/3 ë¶„ì„ ê²°ê³¼ ë¡œë“œ ë° ìŠ¤íƒ€ì¼ ë ˆë²¨ ì§‘ê³„"""
    print(f"  â–¸ STEP2/3 ê²°ê³¼ ë¡œë“œ: {os.path.basename(ANALYSIS_RESULT_FILE)}")
    df = pd.read_excel(ANALYSIS_RESULT_FILE)
    print(f"    - ì›ë³¸ í–‰ ìˆ˜ (ì»¬ëŸ¬ë³„): {len(df)}")

    # ì¤‘ë³µ ì»¬ëŸ¼ ì²˜ë¦¬: 'AIê³„ì‚° ê¸°íšŒë¹„ìš©' (ê³µë°± ì—†ìŒ) ì´ ìˆìœ¼ë©´ 'AI ê³„ì‚° ê¸°íšŒë¹„ìš©' (ê³µë°± ìˆìŒ) ìš°ì„  ì‚¬ìš©
    if "AIê³„ì‚° ê¸°íšŒë¹„ìš©" in df.columns and COL_AI_OPP_COST in df.columns:
        # ê³µë°± ìˆëŠ” ë²„ì „ ì‚¬ìš©, ì—†ëŠ” ë²„ì „ì€ ë¬´ì‹œ
        pass

    # ìˆ˜ì¹˜ ì»¬ëŸ¼ ì•ˆì „ ë³€í™˜
    for col in [COL_TOTAL_ORDER, COL_TOTAL_INBOUND, COL_TOTAL_SALE,
                COL_AI_OPP_COST, COL_AI_ORDER, COL_SELL_RATE]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

    # AI_ì§„ë‹¨ì—ì„œ ëŒ€í‘œ ì§„ë‹¨ ê²°ì •ì„ ìœ„í•œ ìš°ì„ ìˆœìœ„
    diag_priority = {
        "ğŸŸ¢Hit (ì ê¸° ì†Œì§„)": 1,
        "ğŸš¨Early Shortage (5ì›”ì „ í’ˆì ˆ)": 2,
        "âš ï¸Shortage (ì‹œì¦Œì¤‘ í’ˆì ˆ)": 3,
        "âšªNormal": 4,
        "ğŸ”´Risk (ë¶€ì§„)": 5,
    }

    def representative_diag(series):
        """ê°€ì¥ ì‹¬ê°í•œ(ìš°ì„ ìˆœìœ„ ë†’ì€) ì§„ë‹¨ì„ ëŒ€í‘œ ì§„ë‹¨ìœ¼ë¡œ ì„ íƒ"""
        vals = series.dropna().unique()
        if len(vals) == 0:
            return "-"
        return min(vals, key=lambda x: diag_priority.get(x, 99))

    # ìŠ¤íƒ€ì¼ ë ˆë²¨(PART_CD)ë¡œ ì§‘ê³„
    agg_dict = {
        COL_TOTAL_ORDER: "sum",
        COL_TOTAL_INBOUND: "sum",
        COL_TOTAL_SALE: "sum",
        COL_AI_OPP_COST: "sum",
        COL_AI_ORDER: "sum",
        COL_PRICE: "first",
        COL_ITEM_NM: "first",
        COL_SELL_RATE: "mean",
    }

    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì§‘ê³„
    agg_dict = {k: v for k, v in agg_dict.items() if k in df.columns}

    style_summary = df.groupby(COL_PART_CD).agg(agg_dict).reset_index()

    # ëŒ€í‘œ ì§„ë‹¨ ë³„ë„ ì²˜ë¦¬
    if COL_AI_DIAG in df.columns:
        diag_series = df.groupby(COL_PART_CD)[COL_AI_DIAG].apply(representative_diag)
        style_summary = style_summary.merge(diag_series.reset_index(), on=COL_PART_CD, how="left")

    # íŒë§¤ìœ¨ ë°˜ì˜¬ë¦¼
    if COL_SELL_RATE in style_summary.columns:
        style_summary[COL_SELL_RATE] = style_summary[COL_SELL_RATE].round(1)

    print(f"    - ìŠ¤íƒ€ì¼ ìˆ˜ (PART_CDë³„): {len(style_summary)}")
    return style_summary


def get_reference_info(ref_part_cd: str, ref_score: float, style_summary: pd.DataFrame) -> Optional[dict]:
    """ë‹¨ì¼ ìœ ì‚¬ìŠ¤íƒ€ì¼ì˜ ì‹¤ì  ì •ë³´ ì¡°íšŒ"""
    if pd.isna(ref_part_cd) or pd.isna(ref_score) or ref_score < MIN_SCORE:
        return None

    ref_part_cd = str(ref_part_cd).strip()
    match = style_summary[style_summary[COL_PART_CD] == ref_part_cd]
    if match.empty:
        return None

    row = match.iloc[0]
    return {
        "part_cd": ref_part_cd,
        "score": float(ref_score),
        "ì´íŒë§¤": int(row.get(COL_TOTAL_SALE, 0)),
        "ì´ë°œì£¼": int(row.get(COL_TOTAL_ORDER, 0)),
        "ì´ì…ê³ ": int(row.get(COL_TOTAL_INBOUND, 0)),
        "íŒë§¤ìœ¨": float(row.get(COL_SELL_RATE, 0)),
        "ê¸°íšŒë¹„ìš©": int(row.get(COL_AI_OPP_COST, 0)),
        "AIë°œì£¼ëŸ‰": int(row.get(COL_AI_ORDER, 0)),
        "ì§„ë‹¨": str(row.get(COL_AI_DIAG, "-")),
        "íŒë§¤ê°€": int(row.get(COL_PRICE, 0)),
        "ì•„ì´í…œëª…": str(row.get(COL_ITEM_NM, "-")),
    }


def get_top3_references(mapping_row: pd.Series, style_summary: pd.DataFrame) -> List[dict]:
    """ë§µí•‘ í–‰ì—ì„œ Top 3 ìœ ì‚¬ìŠ¤íƒ€ì¼ì˜ ì‹¤ì  ì •ë³´ ì¡°íšŒ"""
    refs = []
    for i in range(1, 4):
        part_col = f"REF_PART_CD_{i}"
        score_col = f"REF_SCORE_{i}"
        ref_part_cd = mapping_row.get(part_col)
        ref_score = mapping_row.get(score_col, 0)
        info = get_reference_info(ref_part_cd, ref_score, style_summary)
        if info is not None:
            info["rank"] = i
            refs.append(info)
    return refs


def determine_confidence(refs: List[dict]) -> str:
    """ìœ ì‚¬ìŠ¤íƒ€ì¼ ë§¤ì¹­ ì‹ ë¢°ë„ íŒì •"""
    if not refs:
        return "none"
    top_score = max(r["score"] for r in refs)
    valid_count = len(refs)

    if top_score >= 0.85 and valid_count >= 2:
        return "high"
    elif top_score >= 0.70 and valid_count >= 1:
        return "medium"
    elif top_score >= 0.50:
        return "low"
    return "none"


def calculate_weighted_baseline(refs: List[dict]) -> dict:
    """Top 3 ìœ ì‚¬ìŠ¤íƒ€ì¼ì˜ ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ë°˜ ê°€ì¤‘í‰ê·  ì‚°ì¶œ"""
    if not refs:
        return {
            "ê°€ì¤‘_íŒë§¤ëŸ‰": 0,
            "ê°€ì¤‘_íŒë§¤ìœ¨": 0,
            "ê°€ì¤‘_ê¸°íšŒë¹„ìš©": 0,
            "ê°€ì¤‘_AIë°œì£¼ëŸ‰": 0,
            "ì¶”ì²œë°œì£¼ëŸ‰": 0,
        }

    total_weight = sum(r["score"] for r in refs)
    if total_weight == 0:
        return {
            "ê°€ì¤‘_íŒë§¤ëŸ‰": 0,
            "ê°€ì¤‘_íŒë§¤ìœ¨": 0,
            "ê°€ì¤‘_ê¸°íšŒë¹„ìš©": 0,
            "ê°€ì¤‘_AIë°œì£¼ëŸ‰": 0,
            "ì¶”ì²œë°œì£¼ëŸ‰": 0,
        }

    weighted_sale = sum(r["score"] * r["ì´íŒë§¤"] for r in refs) / total_weight
    weighted_rate = sum(r["score"] * r["íŒë§¤ìœ¨"] for r in refs) / total_weight
    weighted_cost = sum(r["score"] * r["ê¸°íšŒë¹„ìš©"] for r in refs) / total_weight
    weighted_ai_order = sum(r["score"] * r["AIë°œì£¼ëŸ‰"] for r in refs) / total_weight

    return {
        "ê°€ì¤‘_íŒë§¤ëŸ‰": round(weighted_sale),
        "ê°€ì¤‘_íŒë§¤ìœ¨": round(weighted_rate, 1),
        "ê°€ì¤‘_ê¸°íšŒë¹„ìš©": round(weighted_cost),
        "ê°€ì¤‘_AIë°œì£¼ëŸ‰": round(weighted_ai_order),
        "ì¶”ì²œë°œì£¼ëŸ‰": ceil_10(weighted_ai_order),
    }


def process_recommendations(mapping_df: pd.DataFrame, style_summary: pd.DataFrame) -> List[dict]:
    """ì „ì²´ 26S ìŠ¤íƒ€ì¼ì— ëŒ€í•œ ì¶”ì²œ ë°œì£¼ëŸ‰ ì‚°ì¶œ"""
    results = []
    matched = 0
    unmatched = 0

    for _, row in mapping_df.iterrows():
        new_part_cd = str(row.get("NEW_PART_CD", "")).strip()
        new_item_nm = str(row.get("NEW_ITEM_NM", "")).strip()
        new_class2 = str(row.get("NEW_CLASS2", "")).strip()

        refs = get_top3_references(row, style_summary)
        confidence = determine_confidence(refs)
        baseline = calculate_weighted_baseline(refs)

        if confidence == "none":
            unmatched += 1
        else:
            matched += 1

        rec = {
            "NEW_PART_CD": new_part_cd,
            "NEW_ITEM_NM": new_item_nm,
            "NEW_CLASS2": new_class2,
            "references": refs,
            "confidence": confidence,
            **baseline,
        }
        results.append(rec)

    print(f"    - ë§¤ì¹­ ì„±ê³µ: {matched}, ë§¤ì¹­ ë¶ˆê°€: {unmatched}")
    return results


def save_excel(results: List[dict], output_path: str):
    """ì¶”ì²œ ê²°ê³¼ë¥¼ Excelë¡œ ì €ì¥"""
    rows = []
    for rec in results:
        row = {
            "NEW_PART_CD": rec["NEW_PART_CD"],
            "NEW_ITEM_NM": rec["NEW_ITEM_NM"],
            "NEW_CLASS2": rec["NEW_CLASS2"],
        }

        # Top 1~3 ìœ ì‚¬ìŠ¤íƒ€ì¼ ìƒì„¸
        for i in range(1, 4):
            prefix = f"ìœ ì‚¬ìŠ¤íƒ€ì¼{i}"
            ref = next((r for r in rec["references"] if r["rank"] == i), None)
            if ref:
                row[f"{prefix}_í’ˆë²ˆ"] = ref["part_cd"]
                row[f"{prefix}_ìœ ì‚¬ë„"] = ref["score"]
                row[f"{prefix}_ì´íŒë§¤"] = ref["ì´íŒë§¤"]
                row[f"{prefix}_íŒë§¤ìœ¨"] = ref["íŒë§¤ìœ¨"]
                row[f"{prefix}_ì§„ë‹¨"] = ref["ì§„ë‹¨"]
                row[f"{prefix}_AIë°œì£¼ëŸ‰"] = ref["AIë°œì£¼ëŸ‰"]
            else:
                row[f"{prefix}_í’ˆë²ˆ"] = "-"
                row[f"{prefix}_ìœ ì‚¬ë„"] = "-"
                row[f"{prefix}_ì´íŒë§¤"] = "-"
                row[f"{prefix}_íŒë§¤ìœ¨"] = "-"
                row[f"{prefix}_ì§„ë‹¨"] = "-"
                row[f"{prefix}_AIë°œì£¼ëŸ‰"] = "-"

        # ê°€ì¤‘ ê¸°ì¤€ê°’
        row["ê°€ì¤‘_ì „ì‹œì¦Œ_íŒë§¤ëŸ‰"] = rec["ê°€ì¤‘_íŒë§¤ëŸ‰"] if rec["confidence"] != "none" else "-"
        row["ê°€ì¤‘_ì „ì‹œì¦Œ_íŒë§¤ìœ¨"] = rec["ê°€ì¤‘_íŒë§¤ìœ¨"] if rec["confidence"] != "none" else "-"
        row["ê°€ì¤‘_ì „ì‹œì¦Œ_ê¸°íšŒë¹„ìš©"] = rec["ê°€ì¤‘_ê¸°íšŒë¹„ìš©"] if rec["confidence"] != "none" else "-"
        row["ê°€ì¤‘_ì „ì‹œì¦Œ_AIë°œì£¼ëŸ‰"] = rec["ê°€ì¤‘_AIë°œì£¼ëŸ‰"] if rec["confidence"] != "none" else "-"
        row["26S_ì¶”ì²œë°œì£¼ëŸ‰"] = rec["ì¶”ì²œë°œì£¼ëŸ‰"] if rec["confidence"] != "none" else "-"
        row["confidence"] = rec["confidence"]
        if rec.get("budget_scaled"):
            row["budget_scaled"] = True
            row["original_recommendation"] = rec.get("original_recommendation", "-")

        rows.append(row)

    df = pd.DataFrame(rows)

    with pd.ExcelWriter(output_path, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="26S ë°œì£¼ ì¶”ì²œ")

        # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
        ws = writer.sheets["26S ë°œì£¼ ì¶”ì²œ"]
        for col_idx, col_name in enumerate(df.columns, 1):
            max_len = max(
                len(str(col_name)),
                df[col_name].astype(str).str.len().max() if len(df) > 0 else 0
            )
            ws.column_dimensions[chr(64 + col_idx) if col_idx <= 26
                                  else chr(64 + (col_idx - 1) // 26) + chr(65 + (col_idx - 1) % 26)
                                  ].width = min(max_len + 3, 30)

    print(f"  â–¸ Excel ì €ì¥ ì™„ë£Œ: {os.path.basename(output_path)}")


def save_json(results: List[dict], output_path: str):
    """ì¶”ì²œ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
    total = len(results)
    matched = sum(1 for r in results if r["confidence"] != "none")

    output = {
        "metadata": {
            "new_season": NEW_SEASON,
            "ref_season": REF_SEASON,
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_styles": total,
            "matched_styles": matched,
            "unmatched_styles": total - matched,
        },
        "recommendations": [],
    }

    for rec in results:
        item = {
            "new_part_cd": rec["NEW_PART_CD"],
            "new_item_nm": rec["NEW_ITEM_NM"],
            "new_class2": rec["NEW_CLASS2"],
            "references": [
                {
                    "rank": r["rank"],
                    "part_cd": r["part_cd"],
                    "score": r["score"],
                    "ì´íŒë§¤": r["ì´íŒë§¤"],
                    "íŒë§¤ìœ¨": r["íŒë§¤ìœ¨"],
                    "ì§„ë‹¨": r["ì§„ë‹¨"],
                    "AIë°œì£¼ëŸ‰": r["AIë°œì£¼ëŸ‰"],
                }
                for r in rec["references"]
            ],
            "weighted_baseline": {
                "ê°€ì¤‘_íŒë§¤ëŸ‰": rec["ê°€ì¤‘_íŒë§¤ëŸ‰"],
                "ê°€ì¤‘_íŒë§¤ìœ¨": rec["ê°€ì¤‘_íŒë§¤ìœ¨"],
                "ê°€ì¤‘_ê¸°íšŒë¹„ìš©": rec["ê°€ì¤‘_ê¸°íšŒë¹„ìš©"],
                "ê°€ì¤‘_AIë°œì£¼ëŸ‰": rec["ê°€ì¤‘_AIë°œì£¼ëŸ‰"],
            },
            "ì¶”ì²œë°œì£¼ëŸ‰": rec["ì¶”ì²œë°œì£¼ëŸ‰"],
            "confidence": rec["confidence"],
            "budget_scaled": rec.get("budget_scaled", False),
        }
        if rec.get("budget_scaled"):
            item["original_recommendation"] = rec.get("original_recommendation", 0)
        output["recommendations"].append(item)

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"  â–¸ JSON ì €ì¥ ì™„ë£Œ: {os.path.basename(output_path)}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì˜ˆì‚° ì²œì¥(Budget Ceiling) ìë™ ìŠ¤ì¼€ì¼ë§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BUDGET_CONFIG_FILE = os.path.join(OUTPUT_DIR, "budget_config.json")


def apply_budget_ceiling(results: List[dict]) -> List[dict]:
    """
    budget_config.jsonì´ ì¡´ì¬í•˜ë©´, ì¹´í…Œê³ ë¦¬ë³„ ì¶”ì²œ ë°œì£¼ëŸ‰ í•©ê³„ê°€
    ì˜ˆì‚° ì²œì¥ì„ ì´ˆê³¼í•  ë•Œ ë¹„ë¡€ ì¶•ì†Œí•©ë‹ˆë‹¤.

    - ì²œì¥ ì´í•˜ë©´ ìŠ¤ì¼€ì¼ë§ ì—†ìŒ
    - budget_config.jsonì´ ì—†ìœ¼ë©´ ì œì•½ ì—†ì´ ê¸°ì¡´ ë¡œì§ ìœ ì§€
    - ìŠ¤ì¼€ì¼ë§ëœ í•­ëª©ì— budget_scaled=True, original_recommendation í•„ë“œ ì¶”ê°€
    """
    if not os.path.exists(BUDGET_CONFIG_FILE):
        print("  â–¸ budget_config.json ì—†ìŒ â†’ ì˜ˆì‚° ì œì•½ ì—†ì´ ì§„í–‰")
        return results

    with open(BUDGET_CONFIG_FILE, "r", encoding="utf-8") as f:
        config = json.load(f)

    # ì¹´í…Œê³ ë¦¬ë³„ ì˜ˆì‚° ì²œì¥ ë§¤í•‘
    ceiling_map = {}
    for cat in config.get("category_budgets", []):
        ceiling_map[cat["class2"]] = cat["budget_qty"]

    if not ceiling_map:
        print("  â–¸ budget_config.jsonì— ì¹´í…Œê³ ë¦¬ ì˜ˆì‚° ì—†ìŒ â†’ ìŠ¤í‚µ")
        return results

    print(f"  â–¸ ì˜ˆì‚° ì²œì¥ ì ìš© ì¤‘ (ì´ {config.get('total_budget', 0):,}ì¥)")

    # ì¹´í…Œê³ ë¦¬ë³„ ì¶”ì²œ ë°œì£¼ëŸ‰ í•©ì‚°
    cat_totals = {}
    for rec in results:
        class2 = rec.get("NEW_CLASS2", "")
        qty = rec.get("ì¶”ì²œë°œì£¼ëŸ‰", 0)
        if class2 and qty > 0:
            cat_totals[class2] = cat_totals.get(class2, 0) + qty

    # ì¹´í…Œê³ ë¦¬ë³„ ìŠ¤ì¼€ì¼ë§ ë¹„ìœ¨ ê³„ì‚°
    scale_ratios = {}
    for class2, total_qty in cat_totals.items():
        ceiling = ceiling_map.get(class2)
        if ceiling is not None and total_qty > ceiling and total_qty > 0:
            scale_ratios[class2] = ceiling / total_qty
            print(f"    - {class2}: {total_qty:,} â†’ {ceiling:,} (ìŠ¤ì¼€ì¼ {scale_ratios[class2]:.2f})")
        else:
            if ceiling is not None:
                print(f"    - {class2}: {total_qty:,} â‰¤ {ceiling:,} (ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”)")

    # ìŠ¤ì¼€ì¼ë§ ì ìš©
    scaled_count = 0
    for rec in results:
        class2 = rec.get("NEW_CLASS2", "")
        ratio = scale_ratios.get(class2)
        if ratio is not None and rec.get("ì¶”ì²œë°œì£¼ëŸ‰", 0) > 0:
            original = rec["ì¶”ì²œë°œì£¼ëŸ‰"]
            rec["original_recommendation"] = original
            rec["ì¶”ì²œë°œì£¼ëŸ‰"] = ceil_10(original * ratio)
            rec["budget_scaled"] = True
            scaled_count += 1
        else:
            rec["budget_scaled"] = False

    if scaled_count > 0:
        print(f"    - ìŠ¤ì¼€ì¼ë§ëœ ìŠ¤íƒ€ì¼: {scaled_count}ê±´")
    else:
        print("    - ëª¨ë“  ì¹´í…Œê³ ë¦¬ê°€ ì˜ˆì‚° ì´ë‚´ (ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”)")

    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë©”ì¸ ì‹¤í–‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    print("\nâ—† STEP 4: ìœ ì‚¬ìŠ¤íƒ€ì¼ ë§µí•‘ â†’ 26S ë°œì£¼ ì œì•ˆ\n")

    # 1. ML ë§µí•‘ íŒŒì¼ íƒìƒ‰
    mapping_file = None
    if os.path.exists(DEFAULT_MAPPING_FILE):
        mapping_file = DEFAULT_MAPPING_FILE
    elif os.path.exists(SAMPLE_MAPPING_FILE):
        mapping_file = SAMPLE_MAPPING_FILE
        print("  âš  ì •ì‹ ë§µí•‘ íŒŒì¼ ì—†ìŒ â†’ ìƒ˜í”Œ ë§µí•‘ íŒŒì¼ ì‚¬ìš©")

    if mapping_file is None:
        print("  âš  ë§µí•‘ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ (data/similarity_mapping.csv)")
        print("    â†’ STEP 4ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ë¶„ì„ì€ ì •ìƒ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    # 2. STEP2/3 ë¶„ì„ ê²°ê³¼ í™•ì¸
    if not os.path.exists(ANALYSIS_RESULT_FILE):
        print(f"  âœ— STEP2/3 ë¶„ì„ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {os.path.basename(ANALYSIS_RESULT_FILE)}")
        print("    â†’ STEP 1~3ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

    # 3. ë§µí•‘ ë¡œë“œ
    print(f"  â–¸ ë§µí•‘ íŒŒì¼ ë¡œë“œ: {os.path.basename(mapping_file)}")
    source = get_mapping_source("csv", filepath=mapping_file)
    mapping_df = source.load_mappings()
    print(f"    - 26S ì‹ ê·œ ìŠ¤íƒ€ì¼ ìˆ˜: {len(mapping_df)}")

    # 4. STEP2/3 ë¶„ì„ ê²°ê³¼ ë¡œë“œ & ìŠ¤íƒ€ì¼ ì§‘ê³„
    style_summary = load_analysis_result()

    # 5. ì¶”ì²œ ë°œì£¼ëŸ‰ ì‚°ì¶œ
    print("  â–¸ ì¶”ì²œ ë°œì£¼ëŸ‰ ì‚°ì¶œ ì¤‘...")
    results = process_recommendations(mapping_df, style_summary)

    # 5.5 ì˜ˆì‚° ì²œì¥ ì ìš© (budget_config.jsonì´ ìˆëŠ” ê²½ìš°)
    results = apply_budget_ceiling(results)

    # 6. ì¶œë ¥ ì €ì¥
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    save_excel(results, OUTPUT_EXCEL)
    save_json(results, OUTPUT_JSON)

    # 7. ìš”ì•½ ì¶œë ¥
    total = len(results)
    by_conf = {}
    for r in results:
        by_conf[r["confidence"]] = by_conf.get(r["confidence"], 0) + 1

    print(f"\n  â—† ê²°ê³¼ ìš”ì•½:")
    print(f"    - ì „ì²´ ìŠ¤íƒ€ì¼: {total}")
    for conf in ["high", "medium", "low", "none"]:
        cnt = by_conf.get(conf, 0)
        if cnt > 0:
            print(f"    - {conf}: {cnt}ê±´")


if __name__ == "__main__":
    main()
