"""
STEP 5: ìœ ì‚¬ìŠ¤íƒ€ì¼ ë§µí•‘ ë°ì´í„° ìƒì„± (í”„ë¡ íŠ¸ì—”ë“œìš©)

ì „ì‹œì¦Œ(25S) STEP2/3 ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ML ìœ ì‚¬ìŠ¤íƒ€ì¼ ë§µí•‘ ë°ì´í„°ë¥¼
í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©í•  JSONìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ìœ ì €ê°€ í”„ë¡ íŠ¸ì—”ë“œ Step 3ì—ì„œ ìœ ì‚¬ìŠ¤íƒ€ì¼ì„ í™•ì •í•˜ë©´,
ì„œë²„ APIê°€ í™•ì • ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œë°œì£¼ëŸ‰ì„ ì‚°ì¶œí•©ë‹ˆë‹¤.

ì‹¤í–‰ ìˆœì„œ: STEP1 â†’ STEP2 â†’ STEP3 â†’ STEP4 â†’ STEP5 (ì´ ìŠ¤í¬ë¦½íŠ¸)
"""

import os
import sys
import json
import math
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Dict, List, Optional

import pandas as pd
import numpy as np

# â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")
OUTPUT_DIR = os.path.join(BASE_DIR, "output")
PUBLIC_DIR = os.path.join(BASE_DIR, "public")

ANALYSIS_RESULT_FILE = os.path.join(OUTPUT_DIR, "25S_TimeSeries_Analysis_Result.xlsx")
DEFAULT_MAPPING_FILE = os.path.join(DATA_DIR, "similarity_mapping.csv")
SAMPLE_MAPPING_FILE = os.path.join(DATA_DIR, "similarity_mapping_sample.csv")

OUTPUT_JSON = os.path.join(PUBLIC_DIR, "style_mapping_data.json")

# â”€â”€ ìƒìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MIN_SCORE = 0.50          # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
NEW_SEASON = "26S"
REF_SEASON = "25S"

# STEP2/3 ê²°ê³¼ ì»¬ëŸ¼ëª… (ì‹¤ì œ Excel ê¸°ì¤€)
COL_PART_CD = "PART_CD"
COL_ITEM_NM = "ITEM_NM"
COL_PRICE = "íŒë§¤ê°€"
COL_COLOR_CD = "COLOR_CD"
COL_TOTAL_ORDER = "ì´ë°œì£¼"
COL_TOTAL_INBOUND = "ì´ì…ê³ "
COL_TOTAL_SALE = "ì´íŒë§¤"
COL_SELL_RATE = "ìµœì¢…íŒë§¤ìœ¨"
COL_AI_DIAG = "AI_ì§„ë‹¨"
COL_AI_OPP_COST = "AI ê³„ì‚° ê¸°íšŒë¹„ìš©"
COL_AI_ORDER = "AIì œì•ˆ ë°œì£¼ëŸ‰"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë°ì´í„° ì†ŒìŠ¤ ì¶”ìƒí™”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MappingDataSource(ABC):
    """ML ë§µí•‘ ë°ì´í„° ì†ŒìŠ¤ ì¸í„°í˜ì´ìŠ¤"""
    @abstractmethod
    def load_mappings(self) -> pd.DataFrame:
        """ë§µí•‘ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜.

        í•„ìˆ˜ ì»¬ëŸ¼: NEW_PART_CD, NEW_ITEM_NM, NEW_CLASS2,
                   REF_PART_CD_1~3, REF_SCORE_1~3, MATCHED_ATTRS
        """
        ...


class CSVMappingSource(MappingDataSource):
    """CSV íŒŒì¼ì—ì„œ ë§µí•‘ ë¡œë“œ"""
    def __init__(self, filepath: str):
        self.filepath = filepath

    def load_mappings(self) -> pd.DataFrame:
        df = pd.read_csv(self.filepath, encoding="utf-8-sig")
        return df


class DBMappingSource(MappingDataSource):
    """í–¥í›„ Snowflake ë“± DB ì—°ë™ìš© (ë¯¸êµ¬í˜„)"""
    def __init__(self, **kwargs):
        self.config = kwargs

    def load_mappings(self) -> pd.DataFrame:
        raise NotImplementedError("DB ë§µí•‘ ì†ŒìŠ¤ëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


class APIMappingSource(MappingDataSource):
    """í–¥í›„ API ì—°ë™ìš© (ë¯¸êµ¬í˜„)"""
    def __init__(self, **kwargs):
        self.config = kwargs

    def load_mappings(self) -> pd.DataFrame:
        raise NotImplementedError("API ë§µí•‘ ì†ŒìŠ¤ëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def get_mapping_source(source_type: str = "csv", **kwargs) -> MappingDataSource:
    """íŒ©í† ë¦¬ í•¨ìˆ˜: ì†ŒìŠ¤ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ MappingDataSource ë°˜í™˜"""
    sources = {
        "csv": CSVMappingSource,
        "db": DBMappingSource,
        "api": APIMappingSource,
    }
    cls = sources.get(source_type)
    if cls is None:
        raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì†ŒìŠ¤ íƒ€ì…: {source_type}")
    return cls(**kwargs)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í•µì‹¬ ë¡œì§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def ceil_10(x):
    """10ë‹¨ìœ„ ì˜¬ë¦¼"""
    if pd.isna(x) or x <= 0:
        return 0
    return int(math.ceil(x / 10) * 10)


def load_analysis_result() -> pd.DataFrame:
    """STEP2/3 ë¶„ì„ ê²°ê³¼ ë¡œë“œ ë° ìŠ¤íƒ€ì¼ ë ˆë²¨ ì§‘ê³„"""
    print(f"  â–¸ STEP2/3 ê²°ê³¼ ë¡œë“œ: {os.path.basename(ANALYSIS_RESULT_FILE)}")
    df = pd.read_excel(ANALYSIS_RESULT_FILE)
    print(f"    - ì›ë³¸ í–‰ ìˆ˜ (ì»¬ëŸ¬ë³„): {len(df)}")

    # ì¤‘ë³µ ì»¬ëŸ¼ ì²˜ë¦¬: 'AIê³„ì‚° ê¸°íšŒë¹„ìš©' (ê³µë°± ì—†ìŒ) ì´ ìˆìœ¼ë©´ 'AI ê³„ì‚° ê¸°íšŒë¹„ìš©' (ê³µë°± ìˆìŒ) ìš°ì„  ì‚¬ìš©
    if "AIê³„ì‚° ê¸°íšŒë¹„ìš©" in df.columns and COL_AI_OPP_COST in df.columns:
        # ê³µë°± ìˆëŠ” ë²„ì „ ì‚¬ìš©, ì—†ëŠ” ë²„ì „ì€ ë¬´ì‹œ
        pass

    # ìˆ˜ì¹˜ ì»¬ëŸ¼ ì•ˆì „ ë³€í™˜
    for col in [COL_TOTAL_ORDER, COL_TOTAL_INBOUND, COL_TOTAL_SALE,
                COL_AI_OPP_COST, COL_AI_ORDER, COL_SELL_RATE]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

    # AI_ì§„ë‹¨ì—ì„œ ëŒ€í‘œ ì§„ë‹¨ ê²°ì •ì„ ìœ„í•œ ìš°ì„ ìˆœìœ„
    diag_priority = {
        "ğŸŸ¢Hit (ì ê¸° ì†Œì§„)": 1,
        "ğŸš¨Early Shortage (5ì›”ì „ í’ˆì ˆ)": 2,
        "âš ï¸Shortage (ì‹œì¦Œì¤‘ í’ˆì ˆ)": 3,
        "âšªNormal": 4,
        "ğŸ”´Risk (ë¶€ì§„)": 5,
    }

    def representative_diag(series):
        """ê°€ì¥ ì‹¬ê°í•œ(ìš°ì„ ìˆœìœ„ ë†’ì€) ì§„ë‹¨ì„ ëŒ€í‘œ ì§„ë‹¨ìœ¼ë¡œ ì„ íƒ"""
        vals = series.dropna().unique()
        if len(vals) == 0:
            return "-"
        return min(vals, key=lambda x: diag_priority.get(x, 99))

    # ìŠ¤íƒ€ì¼ ë ˆë²¨(PART_CD)ë¡œ ì§‘ê³„ â€” íŒë§¤ìœ¨ì€ meanì´ ì•„ë‹Œ sum/sumìœ¼ë¡œ ì§ì ‘ ê³„ì‚°
    agg_dict = {
        COL_TOTAL_ORDER: "sum",
        COL_TOTAL_INBOUND: "sum",
        COL_TOTAL_SALE: "sum",
        COL_AI_OPP_COST: "sum",
        COL_AI_ORDER: "sum",
        COL_PRICE: "first",
        COL_ITEM_NM: "first",
    }

    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì§‘ê³„
    agg_dict = {k: v for k, v in agg_dict.items() if k in df.columns}

    style_summary = df.groupby(COL_PART_CD).agg(agg_dict).reset_index()

    # íŒë§¤ìœ¨ = ì´íŒë§¤ / ì´ì…ê³  * 100 (mean ë²„ê·¸ ìˆ˜ì •)
    if COL_TOTAL_SALE in style_summary.columns and COL_TOTAL_INBOUND in style_summary.columns:
        style_summary[COL_SELL_RATE] = (
            style_summary[COL_TOTAL_SALE] / style_summary[COL_TOTAL_INBOUND].replace(0, np.nan) * 100
        ).fillna(0).round(1)

    # ëŒ€í‘œ ì§„ë‹¨ ë³„ë„ ì²˜ë¦¬
    if COL_AI_DIAG in df.columns:
        diag_series = df.groupby(COL_PART_CD)[COL_AI_DIAG].apply(representative_diag)
        style_summary = style_summary.merge(diag_series.reset_index(), on=COL_PART_CD, how="left")

    print(f"    - ìŠ¤íƒ€ì¼ ìˆ˜ (PART_CDë³„): {len(style_summary)}")
    return style_summary


def get_reference_info(ref_part_cd: str, ref_score: float, style_summary: pd.DataFrame) -> Optional[dict]:
    """ë‹¨ì¼ ìœ ì‚¬ìŠ¤íƒ€ì¼ì˜ ì‹¤ì  ì •ë³´ ì¡°íšŒ"""
    if pd.isna(ref_part_cd) or pd.isna(ref_score) or ref_score < MIN_SCORE:
        return None

    ref_part_cd = str(ref_part_cd).strip()
    match = style_summary[style_summary[COL_PART_CD] == ref_part_cd]
    if match.empty:
        return None

    row = match.iloc[0]
    return {
        "part_cd": ref_part_cd,
        "score": float(ref_score),
        "ì´íŒë§¤": int(row.get(COL_TOTAL_SALE, 0)),
        "ì´ë°œì£¼": int(row.get(COL_TOTAL_ORDER, 0)),
        "ì´ì…ê³ ": int(row.get(COL_TOTAL_INBOUND, 0)),
        "íŒë§¤ìœ¨": float(row.get(COL_SELL_RATE, 0)),
        "ê¸°íšŒë¹„ìš©": int(row.get(COL_AI_OPP_COST, 0)),
        "AIë°œì£¼ëŸ‰": int(row.get(COL_AI_ORDER, 0)),
        "ì§„ë‹¨": str(row.get(COL_AI_DIAG, "-")),
        "íŒë§¤ê°€": int(row.get(COL_PRICE, 0)),
        "ì•„ì´í…œëª…": str(row.get(COL_ITEM_NM, "-")),
    }


def get_top3_references(mapping_row: pd.Series, style_summary: pd.DataFrame) -> List[dict]:
    """ë§µí•‘ í–‰ì—ì„œ Top 3 ìœ ì‚¬ìŠ¤íƒ€ì¼ì˜ ì‹¤ì  ì •ë³´ ì¡°íšŒ"""
    refs = []
    for i in range(1, 4):
        part_col = f"REF_PART_CD_{i}"
        score_col = f"REF_SCORE_{i}"
        ref_part_cd = mapping_row.get(part_col)
        ref_score = mapping_row.get(score_col, 0)
        info = get_reference_info(ref_part_cd, ref_score, style_summary)
        if info is not None:
            info["rank"] = i
            refs.append(info)
    return refs


def generate_style_mapping_json(mapping_df: pd.DataFrame, style_summary: pd.DataFrame) -> dict:
    """ì „ì²´ 26S ìŠ¤íƒ€ì¼ì— ëŒ€í•œ ë§µí•‘ JSON ìƒì„± (í”„ë¡ íŠ¸ì—”ë“œìš©)"""
    styles = []
    matched = 0
    unmatched = 0

    for _, row in mapping_df.iterrows():
        new_part_cd = str(row.get("NEW_PART_CD", "")).strip()
        new_item_nm = str(row.get("NEW_ITEM_NM", "")).strip()
        new_class2 = str(row.get("NEW_CLASS2", "")).strip()

        refs = get_top3_references(row, style_summary)

        if refs:
            matched += 1
        else:
            unmatched += 1

        styles.append({
            "new_part_cd": new_part_cd,
            "new_item_nm": new_item_nm,
            "new_class2": new_class2,
            "references": [
                {
                    "rank": r["rank"],
                    "part_cd": r["part_cd"],
                    "item_nm": r["ì•„ì´í…œëª…"],
                    "score": r["score"],
                    "ì´íŒë§¤": r["ì´íŒë§¤"],
                    "ì´ì…ê³ ": r["ì´ì…ê³ "],
                    "íŒë§¤ìœ¨": r["íŒë§¤ìœ¨"],
                    "ì§„ë‹¨": r["ì§„ë‹¨"],
                    "AIë°œì£¼ëŸ‰": r["AIë°œì£¼ëŸ‰"],
                    "ê¸°íšŒë¹„ìš©": r["ê¸°íšŒë¹„ìš©"],
                    "íŒë§¤ê°€": r["íŒë§¤ê°€"],
                }
                for r in refs
            ],
        })

    print(f"    - ë§¤ì¹­ ì„±ê³µ: {matched}, ë§¤ì¹­ ë¶ˆê°€: {unmatched}")

    output = {
        "metadata": {
            "new_season": NEW_SEASON,
            "ref_season": REF_SEASON,
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_styles": len(styles),
            "matched_styles": matched,
            "unmatched_styles": unmatched,
        },
        "styles": styles,
    }
    return output


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë©”ì¸ ì‹¤í–‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    print("\nâ—† STEP 5: ìœ ì‚¬ìŠ¤íƒ€ì¼ ë§µí•‘ ë°ì´í„° ìƒì„± (í”„ë¡ íŠ¸ì—”ë“œìš©)\n")

    # 1. ML ë§µí•‘ íŒŒì¼ íƒìƒ‰
    mapping_file = None
    if os.path.exists(DEFAULT_MAPPING_FILE):
        mapping_file = DEFAULT_MAPPING_FILE
    elif os.path.exists(SAMPLE_MAPPING_FILE):
        mapping_file = SAMPLE_MAPPING_FILE
        print("  âš  ì •ì‹ ë§µí•‘ íŒŒì¼ ì—†ìŒ â†’ ìƒ˜í”Œ ë§µí•‘ íŒŒì¼ ì‚¬ìš©")

    if mapping_file is None:
        print("  âš  ë§µí•‘ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ (data/similarity_mapping.csv)")
        print("    â†’ STEP 5ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ë¶„ì„ì€ ì •ìƒ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    # 2. STEP2/3 ë¶„ì„ ê²°ê³¼ í™•ì¸
    if not os.path.exists(ANALYSIS_RESULT_FILE):
        print(f"  âœ— STEP2/3 ë¶„ì„ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {os.path.basename(ANALYSIS_RESULT_FILE)}")
        print("    â†’ STEP 1~4ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

    # 3. ë§µí•‘ ë¡œë“œ
    print(f"  â–¸ ë§µí•‘ íŒŒì¼ ë¡œë“œ: {os.path.basename(mapping_file)}")
    source = get_mapping_source("csv", filepath=mapping_file)
    mapping_df = source.load_mappings()
    print(f"    - 26S ì‹ ê·œ ìŠ¤íƒ€ì¼ ìˆ˜: {len(mapping_df)}")

    # 4. STEP2/3 ë¶„ì„ ê²°ê³¼ ë¡œë“œ & ìŠ¤íƒ€ì¼ ì§‘ê³„
    style_summary = load_analysis_result()

    # 5. ë§µí•‘ JSON ìƒì„±
    print("  â–¸ ë§µí•‘ ë°ì´í„° ìƒì„± ì¤‘...")
    output = generate_style_mapping_json(mapping_df, style_summary)

    # 6. JSON ì €ì¥
    os.makedirs(PUBLIC_DIR, exist_ok=True)
    with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    print(f"  â–¸ JSON ì €ì¥ ì™„ë£Œ: {os.path.basename(OUTPUT_JSON)}")

    # 7. ìš”ì•½ ì¶œë ¥
    meta = output["metadata"]
    print(f"\n  â—† ê²°ê³¼ ìš”ì•½:")
    print(f"    - ì „ì²´ ìŠ¤íƒ€ì¼: {meta['total_styles']}")
    print(f"    - ë§¤ì¹­ ì„±ê³µ: {meta['matched_styles']}")
    print(f"    - ë§¤ì¹­ ë¶ˆê°€: {meta['unmatched_styles']}")


if __name__ == "__main__":
    main()
