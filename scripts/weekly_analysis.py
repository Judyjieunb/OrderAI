import pandas as pd
import json
from config_loader import get_sell_through_threshold, get_early_stockout_date, get_shortage_cutoff_date

_ST_THRESHOLD = get_sell_through_threshold()
_EARLY_STOCKOUT_DATE = get_early_stockout_date()
_SHORTAGE_CUTOFF_DATE = get_shortage_cutoff_date()

# 1. ë°ì´í„° ë¡œë“œ (íŒŒì¼ëª…ì— ë§ê²Œ ìˆ˜ì •)
file_path = '../data/weekly_dx25s.xlsx - Data.csv'
try:
    df = pd.read_csv(file_path)
except:
    # ì—‘ì…€ íŒŒì¼ì¼ ê²½ìš° (ì²« ë²ˆì§¸ ì‹œíŠ¸)
    df = pd.read_excel('../data/weekly_dx25s.xlsx', sheet_name=0)

# 2. ì „ì²˜ë¦¬: 25S ì‹œì¦Œ('ë‹¹í•´') ë°ì´í„° í•„í„°ë§ ë° ë‚ ì§œ ë³€í™˜
df_process = df[df['PERIOD'] == 'ë‹¹í•´'].copy()
df_process['END_DT'] = pd.to_datetime(df_process['END_DT'])

# -------------------------------------------------------
# 3. í•µì‹¬ ë¡œì§: ìŠ¤íƒ€ì¼ë³„ ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„ í•¨ìˆ˜
# -------------------------------------------------------
# -------------------------------------------------------
# 3. í•µì‹¬ ë¡œì§: ìŠ¤íƒ€ì¼ë³„ ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„ í•¨ìˆ˜
# -------------------------------------------------------
def generate_chart_data(group, init_date):
    """
    ê·¸ë£¹(ìŠ¤íƒ€ì¼ or ì»¬ëŸ¬)ì˜ Chart JSON ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    íŒë§¤ ì‹œì‘(ìµœì´ˆì…ê³ ì¼) 4ì£¼ ì „ë¶€í„° ë°ì´í„° í¬í•¨
    """
    chart_data = []
    reorder_count = 0
    
    # ìµœì´ˆì…ê³ ì¼ 4ì£¼ ì „ ê³„ì‚°
    cutoff_date = None
    if pd.notnull(init_date):
        cutoff_date = init_date - pd.Timedelta(days=28)  # 4ì£¼ = 28ì¼
    
    # ê·¸ë£¹ë³„ ì¬ê³ , íŒë§¤, ì…ê³  ê³„ì‚° (ì´ë¯¸ ë‚ ì§œë³„ë¡œ ì •ë ¬ëœ ìƒíƒœë¼ê³  ê°€ì •)
    for _, row in group.iterrows():
        # ìµœì´ˆì…ê³ ì¼ 4ì£¼ ì „ ì´í›„ ë°ì´í„°ë§Œ í¬í•¨
        if cutoff_date is not None and row['END_DT'] < cutoff_date:
            continue
            
        label = ''
        if row['STOR_QTY_KR'] > 0 and pd.notnull(init_date) and row['END_DT'] > init_date:
            reorder_count += 1
            label = f'{reorder_count}ì°¨ ë¦¬ì˜¤ë”' if reorder_count > 0 else 'ë¦¬ì˜¤ë”'
        elif row.get('Sell_Through', 0) >= _ST_THRESHOLD and label == '':
            label = 'ì¬ê³ ë¶€ì¡±'
            
        chart_data.append({
            'date': row['END_DT'].strftime('%m/%d'),
            'sale': int(row['SALE_QTY_CNS']),
            'stock': int(row['STOCK_QTY_KR']) if 'STOCK_QTY_KR' in row else int(row.get('STOCK_QTY', 0)),
            'in': int(row['STOR_QTY_KR']),
            'label': label
        })
    return chart_data

def analyze_style_pattern(group, is_total=False):
    # ë‚ ì§œìˆœ ì •ë ¬
    group = group.sort_values('END_DT')
    
    # [A] ê¸°ì´ˆ ì¬ê³  ë° ëˆ„ì  íë¦„ ê³„ì‚°
    # ëˆ„ì  ì…ê³  (STOR_QTY_KR)
    group['Cum_In'] = group['STOR_QTY_KR'].cumsum()
    # ëˆ„ì  íŒë§¤ (SALE_QTY_CNS)
    group['Cum_Sale'] = group['SALE_QTY_CNS'].cumsum()
    
    # íŒë§¤ìœ¨ (Sell-Through)
    group['Sell_Through'] = group.apply(
        lambda x: x['Cum_Sale'] / x['Cum_In'] if x['Cum_In'] > 0 else 0, axis=1
    )
    
    # [B] ì¤‘ìš” ì‹œì  ì¶”ì¶œ
    # 1. ìµœì´ˆ ì…ê³ ì¼
    in_stock = group[group['STOR_QTY_KR'] > 0]
    init_date = in_stock['END_DT'].min() if not in_stock.empty else pd.NaT
    
    # 2. ë¦¬ì˜¤ë” ë°œìƒì¼ (ìµœì´ˆ ì…ê³ ì¼ + 14ì¼ ì´í›„ ì…ê³ ê°€ ìˆëŠ” ê²½ìš°)
    reorders = []
    if pd.notnull(init_date):
        reorder_rows = group[
            (group['END_DT'] > init_date + pd.Timedelta(days=14)) & 
            (group['STOR_QTY_KR'] > 0)
        ]
        reorders = reorder_rows['END_DT'].dt.strftime('%m/%d').tolist()
    
    # 3. ê²°í’ˆ ì„ë°• ì‹œì  (ëˆ„ì  íŒë§¤ìœ¨ 70% ìµœì´ˆ ëŒíŒŒ ì£¼ì°¨)
    # ë‹¨, ì…ê³ ê°€ 10ì¥ ì´ìƒì¸ ìœ ì˜ë¯¸í•œ ê²½ìš°ë§Œ ì²´í¬
    stock_out_row = group[(group['Sell_Through'] >= _ST_THRESHOLD) & (group['Cum_In'] > 10)]
    stock_out_date = stock_out_row['END_DT'].min() if not stock_out_row.empty else pd.NaT
    
    # [C] AI ì§„ë‹¨ (Diagnosis)
    total_sale = group['SALE_QTY_CNS'].sum()
    final_str = group['Sell_Through'].iloc[-1] if not group.empty else 0
    total_in = group['STOR_QTY_KR'].sum()
    total_order = group['ORDER_QTY'].sum() if 'ORDER_QTY' in group.columns else total_in
    
    status = "âšªNormal"
    if pd.notnull(stock_out_date):
        if stock_out_date <= _EARLY_STOCKOUT_DATE:
            status = "ğŸš¨Early Shortage (5ì›”ì „ í’ˆì ˆ)"
        elif stock_out_date <= _SHORTAGE_CUTOFF_DATE:
            status = "âš ï¸Shortage (ì‹œì¦Œì¤‘ í’ˆì ˆ)"
        else:
            status = "ğŸŸ¢Hit (ì ê¸° ì†Œì§„)"
    elif final_str >= 0.8:
        status = "ğŸŸ¢Hit (ê³ íš¨ìœ¨)"
    elif final_str < 0.55:
        status = "ğŸ”´Risk (ë¶€ì§„)"
    # else: 55% <= final_str < 80% -> Normal (ê¸°ë³¸ê°’ ìœ ì§€)

    # [D] ì°¨íŠ¸ ë°ì´í„° ìƒì„±
    chart_data = generate_chart_data(group, init_date)

    # íŒë§¤ê°€ (TAG_PRICE) ì¶”ì¶œ - ê·¸ë£¹ ë‚´ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
    tag_price = group['TAG_PRICE'].iloc[0] if 'TAG_PRICE' in group.columns else 0

    return pd.Series({
        'ìµœì´ˆì…ê³ ': init_date.strftime('%Y-%m-%d') if pd.notnull(init_date) else '-',
        'ê²°í’ˆì‹œì (70%)': stock_out_date.strftime('%Y-%m-%d') if pd.notnull(stock_out_date) else '-',
        'ë¦¬ì˜¤ë”ì…ê³ ì¼': ', '.join(reorders),
        'ì´ë°œì£¼': total_order,
        'ì´ì…ê³ ': total_in,
        'ì´íŒë§¤': total_sale,
        'ìµœì¢…íŒë§¤ìœ¨': round(final_str * 100, 1),
        'AI_ì§„ë‹¨': status,
        'íŒë§¤ê°€': int(tag_price),
        'Chart_JSON': json.dumps(chart_data, ensure_ascii=False) # JSON ë¬¸ìì—´ë¡œ ì €ì¥
    })

# 4. ì „ì²´ ìŠ¤íƒ€ì¼ ë¶„ì„ ì‹¤í–‰
print("ë°ì´í„° ë¶„ì„ ì¤‘...")
result_df = df_process.groupby(['ITEM_NM', 'PART_CD', 'COLOR_CD']).apply(analyze_style_pattern).reset_index()

# 5. ê²°ê³¼ ì €ì¥
# 5-1. ìƒˆë¡œìš´ ì»¬ëŸ¼ ì¶”ê°€ (ê¸°íšŒë¹„ìš© ë¶„ì„ìš©)
result_df['AI ê³„ì‚° ê¸°íšŒë¹„ìš©'] = 0  # ì´ˆê¸°ê°’ 0, ai_sales_loss_v2.pyì—ì„œ ì—…ë°ì´íŠ¸
result_df['AIì œì•ˆ ë°œì£¼ëŸ‰'] = 0      # ì´ˆê¸°ê°’ 0, ai_sales_loss_v2.pyì—ì„œ ì—…ë°ì´íŠ¸

# 5-2. ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬ (íŒë§¤ê°€ë¥¼ PART_CD ì˜¤ë¥¸ìª½ìœ¼ë¡œ, ê¸°íšŒë¹„ìš© ì»¬ëŸ¼ì„ AI_ì§„ë‹¨ ì˜¤ë¥¸ìª½ìœ¼ë¡œ)
column_order = [
    'ITEM_NM', 'PART_CD', 'íŒë§¤ê°€', 'COLOR_CD',
    'ìµœì´ˆì…ê³ ', 'ê²°í’ˆì‹œì (70%)', 'ë¦¬ì˜¤ë”ì…ê³ ì¼',
    'ì´ë°œì£¼', 'ì´ì…ê³ ', 'ì´íŒë§¤', 'ìµœì¢…íŒë§¤ìœ¨',
    'AI_ì§„ë‹¨', 'AI ê³„ì‚° ê¸°íšŒë¹„ìš©', 'AIì œì•ˆ ë°œì£¼ëŸ‰',
    'Chart_JSON'
]
result_df = result_df[column_order]

# 5-3. ì—‘ì…€ ì €ì¥ (Chart_JSON ì œì™¸)
result_df.drop(columns=['Chart_JSON']).to_excel('../output/25S_TimeSeries_Analysis_Result.xlsx', index=False)
print("* ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: ../output/25S_TimeSeries_Analysis_Result.xlsx")

# 6. ëŒ€ì‹œë³´ë“œìš© JSON ì¶œë ¥ ë° ì €ì¥ (ëŒ€í‘œ ì„±ê³µ/ì‹¤íŒ¨ ì‚¬ë¡€ 1ê±´ì”©)
# 6. ëŒ€ì‹œë³´ë“œìš© JSON ì¶œë ¥ ë° ì €ì¥ (ëŒ€í‘œ ì„±ê³µ/ì‹¤íŒ¨ ì‚¬ë¡€ -> Total + Colors êµ¬ì¡°ë¡œ ë³€í™˜)
print("\n--- [ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„± ì¤‘ (Total + Colors)] ---")

def create_dashboard_entry(part_cd, color_cd, raw_df, anal_df):
    """
    íŠ¹ì • ìŠ¤íƒ€ì¼(part_cd)ì— ëŒ€í•œ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±
    - total: í•´ë‹¹ ìŠ¤íƒ€ì¼ì˜ ëª¨ë“  ì»¬ëŸ¬ í•©ì‚° ë°ì´í„°
    - colors: ê° ì»¬ëŸ¬ë³„ ë°ì´í„° ë§µ
    """
    # 1. Total Data ìƒì„± (Raw Dataì—ì„œ ë‹¤ì‹œ ì§‘ê³„)
    style_raw_mask = (raw_df['PART_CD'] == part_cd)
    style_raw = raw_df[style_raw_mask].copy()
    
    # ë‚ ì§œë³„ë¡œ ëª¨ë“  ì»¬ëŸ¬ í•©ì‚°
    agg_dict = {
        'STOR_QTY_KR': 'sum',
        'SALE_QTY_CNS': 'sum',
        'STOCK_QTY_KR': 'sum',
        'TAG_PRICE': 'first'
    }
    # ORDER_QTY ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì¶”ê°€
    if 'ORDER_QTY' in style_raw.columns:
        agg_dict['ORDER_QTY'] = 'sum'
    
    style_total_raw = style_raw.groupby('END_DT').agg(agg_dict).reset_index()
    
    # Total ë¶„ì„ ì‹¤í–‰
    total_analysis = analyze_style_pattern(style_total_raw, is_total=True)
    
    # ITEM_NM, PRDT_NM ì¶”ì¶œ
    item_nm = style_raw['ITEM_NM'].iloc[0]
    prdt_nm = style_raw['PRDT_NM'].iloc[0] if 'PRDT_NM' in style_raw.columns else ''
    
    total_entry = {
        'chartData': json.loads(total_analysis['Chart_JSON']),
        'itemInfo': {
            'name': str(item_nm),
            'code': str(part_cd),
            'color': 'ì „ì²´',
            'price': int(total_analysis['íŒë§¤ê°€']),
            'prdt_nm': str(prdt_nm)
        },
        'analysis': {
            'ìµœì´ˆì…ê³ ': str(total_analysis['ìµœì´ˆì…ê³ ']),
            'ê²°í’ˆì‹œì ': str(total_analysis['ê²°í’ˆì‹œì (70%)']),
            'ë¦¬ì˜¤ë”ì…ê³ ì¼': str(total_analysis['ë¦¬ì˜¤ë”ì…ê³ ì¼']),
            'ì´ë°œì£¼': int(total_analysis['ì´ë°œì£¼']),
            'ì´ì…ê³ ': int(total_analysis['ì´ì…ê³ ']),
            'ì´íŒë§¤': int(total_analysis['ì´íŒë§¤']),
            'ìµœì¢…íŒë§¤ìœ¨': float(total_analysis['ìµœì¢…íŒë§¤ìœ¨']),
            'AI_ì§„ë‹¨': str(total_analysis['AI_ì§„ë‹¨'])
        }
    }
    
    # 2. Colors Data ìˆ˜ì§‘ (ì´ë¯¸ ë¶„ì„ëœ anal_df í™œìš©)
    # í•´ë‹¹ ìŠ¤íƒ€ì¼ì˜ ëª¨ë“  ì»¬ëŸ¬ ì°¾ê¸°
    colors_anal = anal_df[anal_df['PART_CD'] == part_cd]
    colors_entry = {}
    
    for _, row in colors_anal.iterrows():
        c_code = str(row['COLOR_CD'])
        colors_entry[c_code] = {
            'chartData': json.loads(row['Chart_JSON']),
            'itemInfo': {
                'name': str(row['ITEM_NM']),
                'code': str(row['PART_CD']),
                'color': c_code,
                'price': int(row['íŒë§¤ê°€']),
                'prdt_nm': str(prdt_nm)
            },
            'analysis': {
                'ìµœì´ˆì…ê³ ': str(row['ìµœì´ˆì…ê³ ']),
                'ê²°í’ˆì‹œì ': str(row['ê²°í’ˆì‹œì (70%)']),
                'ë¦¬ì˜¤ë”ì…ê³ ì¼': str(row['ë¦¬ì˜¤ë”ì…ê³ ì¼']),
                'ì´ë°œì£¼': int(row['ì´ë°œì£¼']),
                'ì´ì…ê³ ': int(row['ì´ì…ê³ ']),
                'ì´íŒë§¤': int(row['ì´íŒë§¤']),
                'ìµœì¢…íŒë§¤ìœ¨': float(row['ìµœì¢…íŒë§¤ìœ¨']),
                'AI_ì§„ë‹¨': str(row['AI_ì§„ë‹¨'])
            }
        }
        
    return {
        'total': total_entry,
        'colors': colors_entry
    }

# ì§„ë‹¨ë³„ í•„í„° ì •ì˜
diagnosis_filters = {
    # Success ê·¸ë£¹
    'hit': result_df['AI_ì§„ë‹¨'] == 'ğŸŸ¢Hit (ì ê¸° ì†Œì§„)',
    'normal': result_df['AI_ì§„ë‹¨'] == 'âšªNormal',
    # Failure ê·¸ë£¹
    'early_shortage': result_df['AI_ì§„ë‹¨'] == 'ğŸš¨Early Shortage (5ì›”ì „ í’ˆì ˆ)',
    'shortage': result_df['AI_ì§„ë‹¨'] == 'âš ï¸Shortage (ì‹œì¦Œì¤‘ í’ˆì ˆ)',
    'risk': result_df['AI_ì§„ë‹¨'] == 'ğŸ”´Risk (ë¶€ì§„)'
}

# ìƒˆë¡œìš´ JSON êµ¬ì¡°: success/failure í•˜ìœ„ì— ì§„ë‹¨ë³„ ë¶„ë¥˜
dashboard_data = {
    'success': {
        'hit': [],
        'normal': []
    },
    'failure': {
        'early_shortage': [],
        'shortage': [],
        'risk': []
    }
}

# ê° ì§„ë‹¨ë³„ë¡œ ìŠ¤íƒ€ì¼ ìˆ˜ì§‘
def collect_styles_by_diagnosis(diagnosis_key, filter_mask, group_key):
    """ì§„ë‹¨ë³„ ìŠ¤íƒ€ì¼ ìˆ˜ì§‘ í•¨ìˆ˜"""
    candidates = result_df[filter_mask].sort_values('ì´íŒë§¤', ascending=False)
    if candidates.empty:
        return 0

    part_codes = candidates['PART_CD'].unique()
    count = 0

    for part_cd in part_codes:
        part_rows = candidates[candidates['PART_CD'] == part_cd]
        representative_row = part_rows.iloc[0]
        color_cd = representative_row['COLOR_CD']

        entry = create_dashboard_entry(part_cd, color_cd, df_process, result_df)
        dashboard_data[group_key][diagnosis_key].append(entry)
        count += 1

    return count

# Success ê·¸ë£¹ ìˆ˜ì§‘
print("\n[Success ê·¸ë£¹]")
hit_count = collect_styles_by_diagnosis('hit', diagnosis_filters['hit'], 'success')
print(f"  - ğŸŸ¢Hit (ì ê¸° ì†Œì§„): {hit_count}ê°œ ìŠ¤íƒ€ì¼")

normal_count = collect_styles_by_diagnosis('normal', diagnosis_filters['normal'], 'success')
print(f"  - âšªNormal: {normal_count}ê°œ ìŠ¤íƒ€ì¼")

# Failure ê·¸ë£¹ ìˆ˜ì§‘
print("\n[Failure ê·¸ë£¹]")
early_shortage_count = collect_styles_by_diagnosis('early_shortage', diagnosis_filters['early_shortage'], 'failure')
print(f"  - ğŸš¨Early Shortage (5ì›”ì „ í’ˆì ˆ): {early_shortage_count}ê°œ ìŠ¤íƒ€ì¼")

shortage_count = collect_styles_by_diagnosis('shortage', diagnosis_filters['shortage'], 'failure')
print(f"  - âš ï¸Shortage (ì‹œì¦Œì¤‘ í’ˆì ˆ): {shortage_count}ê°œ ìŠ¤íƒ€ì¼")

risk_count = collect_styles_by_diagnosis('risk', diagnosis_filters['risk'], 'failure')
print(f"  - ğŸ”´Risk (ë¶€ì§„): {risk_count}ê°œ ìŠ¤íƒ€ì¼")

total_count = hit_count + normal_count + early_shortage_count + shortage_count + risk_count
print(f"\n* ì´ {total_count}ê°œ ìŠ¤íƒ€ì¼ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„± ì™„ë£Œ")

# JSON íŒŒì¼ë¡œ ì €ì¥ (ë£¨íŠ¸ ë° public í´ë”)
import os

# output í´ë”ì— ì €ì¥
with open('../output/dashboard_data.json', 'w', encoding='utf-8') as f:
    json.dump(dashboard_data, f, ensure_ascii=False, indent=2)

# public í´ë”ì—ë„ ì €ì¥ (React ì•±ìš©)
os.makedirs('../public', exist_ok=True)
with open('../public/dashboard_data.json', 'w', encoding='utf-8') as f:
    json.dump(dashboard_data, f, ensure_ascii=False, indent=2)

print("* ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì €ì¥ ì™„ë£Œ: dashboard_data.json (êµ¬ì¡°: Total + Colors)")